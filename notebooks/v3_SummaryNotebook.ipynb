{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary Page\n",
    "\n",
    "## Online Appendix of \"International News Coverage and Foreign Image Building\"\n",
    "\n",
    "### Gento Kato (Nov. 4, 2017)\n",
    "\n",
    "All results and codes in the paper are presented in the *jupyter notebook* files below. For those who wish to replicate results using code files, check <code>codes</code> directory for original code files.\n",
    "\n",
    "## 1. Data Processing\n",
    "\n",
    "All files except for \"Data Processing 3\" can be executable by **R**. \"Data Processing 3\" uses **Python** to conduct machine-learning of directional coverage. Note that the procedure is *cummulative*, one needs to execute the files with older numbers are dependent on the data produced in the younger numbered files Most of the output data files are already created, so it is acceptable to skip some procedures.\n",
    "\n",
    "### [Data Processing 0: Original Data Description](v3_Data0_DataDescription.ipynb)\n",
    "\n",
    "The description of the original headline-level data. Briefly explain how the automated codings for US, China, South Korea and North Korea are conducted (this is separately done by the software called *KH Coder*).\n",
    "\n",
    "### [Data Processing 1: Manual Coding Reliability & Export of Training Codes](v3_Data1_ManualCodingTests.ipynb)\n",
    "\n",
    "Exports the inter-coder reliability for the manual coding of the directional coverage. Also, it considers several ways to export training codes for supervised machine-learning conducted in \"Data Processing 3.\"\n",
    "\n",
    "### [Data Processing 2: Merge Manual Coding & Apply Isomorphic Analysis](v3_Data2_HeadlineWrdMat.ipynb)\n",
    "\n",
    "Merge manually coded cases with the full data of headlines. Also, conduct morphological analysis of the headline texts, and create word appearance matrix for each country (US, China, South Korea, North Korea) to be used in \"Data Processing 3.\"\n",
    "\n",
    "### [Data Processing 3: Predicting Tones of Newspaper Headlines](v3_Data3_SupervisedLearning.ipynb)\n",
    "\n",
    "Conduct machine-learning of directional coverage. The results from Logit Classifier and Random Forest (RF) classifer are compared. (Note: the excecution of this file generates heavy files that cannot be uploaded. To obtain those heavy files, manually create <code>data_heavy</code> directory at the same level as <code>data</code> directory, then exceucte codes.)\n",
    "\n",
    "### [Data Processing 4:  Automated Coding of Headline Level Country Subsets](v3_Data4_HeadlineSubset.ipynb)\n",
    "\n",
    "Conduct automated coding (text search) of state/region relevant texts (except for US, China, South Korea, and North Korea) and issue frames appeared in US, China, South Korea, and North Korea relevant headlines. Create headline-level state/region subsets for the subsequent step.\n",
    "\n",
    "### [Data Processing 5:  Monthly Aggregation & Merge of Datasets](v3_Data5_MonthlySubset.ipynb)\n",
    "\n",
    "Aggregate head-line level datasets by month to generate monthly news coverage variables. Also, merge the Jiji public opinion survey data and bilateral trade data to the news coverage dataset. The datasets created here are used in the time-series analysis.\n",
    "\n",
    "## 2. Analysis\n",
    "\n",
    "All analyses are conducted by **R**.\n",
    "\n",
    "### [Analysis 0: Checking Coding Validity](v3_Analysis0_CodingValidity.ipynb)\n",
    "\n",
    "Compare the different aggregation procedures for directional coverage. Table 2 in the paper is generated from the analysis in this file.\n",
    "\n",
    "### [Analysis: Time Series Analysis](v3_Analysis_TimeSeries.ipynb)\n",
    "\n",
    "Conduct time-series analysis. Produces core results for the paper. \n",
    "\n",
    "## 3. Figures & Tables\n",
    "\n",
    "All figures and tables are created by **R**.\n",
    "\n",
    "### [Figures & Tables: Time Series Analysis](v3_Figures_TimeSeries.ipynb)\n",
    "\n",
    "Figures and Tables used in the paper.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
