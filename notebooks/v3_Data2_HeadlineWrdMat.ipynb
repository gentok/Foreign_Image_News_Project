{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing 2: Merge Manual Coding & Apply Isomorphic Analysis\n",
    "\n",
    "## Online Appendix of \"International News Coverage and Foreign Image Building\"\n",
    "\n",
    "### Gento Kato (Nov. 4, 2017)\n",
    "\n",
    "*Back to [Summary Page](v3_SummaryNotebook.ipynb)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>  \n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       "  if (code_show){\n",
       "    $('div.input').hide();\n",
       "  } else {\n",
       "    $('div.input').show();\n",
       "  }\n",
       "  code_show = !code_show\n",
       "}  \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "  <form action=\"javascript:code_toggle()\">\n",
       "    <input type=\"submit\" value=\"Click here to toggle on/off the raw code.\">\n",
       " </form>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#################################################################################\n",
    "## File Name: v3_Data2_HeadlineWrdMat.R                                        ##\n",
    "## Creation Date: 4 Nov 2016                                                   ##\n",
    "## Author: Gento Kato                                                          ##\n",
    "## Project: Foreign Image News Project                                         ##\n",
    "## Purpose: Conduct Isomorphic Analysis and Create RMeCab Dataset              ##\n",
    "#################################################################################\n",
    "\n",
    "## For Jupyter Notebook (Ignore if Using Other Software) ##\n",
    "library(IRdisplay)\n",
    "\n",
    "display_html(\n",
    "'<script>  \n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    "  if (code_show){\n",
    "    $(\\'div.input\\').hide();\n",
    "  } else {\n",
    "    $(\\'div.input\\').show();\n",
    "  }\n",
    "  code_show = !code_show\n",
    "}  \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "  <form action=\"javascript:code_toggle()\">\n",
    "    <input type=\"submit\" value=\"Click here to toggle on/off the raw code.\">\n",
    " </form>'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Packages and Set Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'C:/GoogleDrive/Projects/Agenda-Setting Persuasion Framing/Foreign_Image_News_Project'"
      ],
      "text/latex": [
       "'C:/GoogleDrive/Projects/Agenda-Setting Persuasion Framing/Foreign\\_Image\\_News\\_Project'"
      ],
      "text/markdown": [
       "'C:/GoogleDrive/Projects/Agenda-Setting Persuasion Framing/Foreign_Image_News_Project'"
      ],
      "text/plain": [
       "[1] \"C:/GoogleDrive/Projects/Agenda-Setting Persuasion Framing/Foreign_Image_News_Project\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#################\n",
    "## Preparation ##\n",
    "#################\n",
    "\n",
    "## Clear Workspace\n",
    "rm(list=ls())\n",
    "\n",
    "## Library Required Packages\n",
    "# ** NEED Current MeCab Installation prior to installing RMeCab **\n",
    "#install.packages (\"RMeCab\", repos = \"http://rmecab.jp/R\")\n",
    "library(RMeCab); library(rprojroot); library(xtable)\n",
    "\n",
    "## Set Working Directory (Automatically or Manually) ##\n",
    "#setwd(dirname(rstudioapi::getActiveDocumentContext()$path)); setwd(../) #In RStudio\n",
    "projdir <- find_root(has_file(\"README.md\")); projdir; setwd(projdir) #In Atom\n",
    "#setwd(\"C:/GoogleDrive/Projects/Agenda-Setting Persuasion Framing/Foreign_Image_News_Project\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data\n",
    "\n",
    "The full dataset of headline is imported as <code>hldata</code>, and training codes dataset is imported as <code>coding_data</code>. Two datasets are merged by the ID variable included in <code>sample_selection</code> dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'coding_data'</li>\n",
       "\t<li>'hldata'</li>\n",
       "\t<li>'projdir'</li>\n",
       "\t<li>'sample_selection'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'coding\\_data'\n",
       "\\item 'hldata'\n",
       "\\item 'projdir'\n",
       "\\item 'sample\\_selection'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'coding_data'\n",
       "2. 'hldata'\n",
       "3. 'projdir'\n",
       "4. 'sample_selection'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"coding_data\"      \"hldata\"           \"projdir\"          \"sample_selection\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#########################\n",
    "## Data Import & Merge ##\n",
    "#########################\n",
    "\n",
    "# Read Headline Level Data\n",
    "hldata<-read.csv(\"data/allheadline.csv\",fileEncoding = \"CP932\")\n",
    "\n",
    "# Read Coding Data\n",
    "sample_selection <- read.csv(\"data/sample_selection.csv\",fileEncoding = \"CP932\")\n",
    "coding_data <- read.csv(\"data/trainingcode.csv\",fileEncoding = \"CP932\")\n",
    "\n",
    "ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Manually-Coded Dataset with Full Dataset\n",
    "\n",
    "#### Training Code by the Majority Rule (using Original Codes) \n",
    "\n",
    "In here, the training negative and positive codes are constructed by the simple majority rule. For each of the category, if two or more coders assign the same directional codes, the case is considered to as directional. Two codes are considered independently, so in the case of 2-2 split of negative/positive codes, both negative and positive codes can be assigned to the same case. The resultant training codes are then merged to the full dataset using <code>sample_selection</code> dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################################\n",
    "## Merge Original Coding Data into Full Dataset ##\n",
    "##################################################\n",
    "\n",
    "#### 1. Use the Proportion Within Coders (with Fixed Data) ####\n",
    "\n",
    "## Create Mean Coding (Negative/Positive Probability)\n",
    "uscode_neg <- as.data.frame((coding_data[,grep(\"_us\",names(coding_data))]==1)*1)\n",
    "chncode_neg <- as.data.frame((coding_data[,grep(\"_chn\",names(coding_data))]==1)*1)\n",
    "skocode_neg <- as.data.frame((coding_data[,grep(\"_sko\",names(coding_data))]==1)*1)\n",
    "nkocode_neg <- as.data.frame((coding_data[,grep(\"_nko\",names(coding_data))]==1)*1)\n",
    "uscode_pos <- as.data.frame((coding_data[,grep(\"_us\",names(coding_data))]==3)*1)\n",
    "chncode_pos <- as.data.frame((coding_data[,grep(\"_chn\",names(coding_data))]==3)*1)\n",
    "skocode_pos <- as.data.frame((coding_data[,grep(\"_sko\",names(coding_data))]==3)*1)\n",
    "nkocode_pos <- as.data.frame((coding_data[,grep(\"_nko\",names(coding_data))]==3)*1)\n",
    "\n",
    "coding_data$prneg_us <- NA\n",
    "coding_data$prneg_chn <- NA\n",
    "coding_data$prneg_sko <- NA\n",
    "coding_data$prneg_nko <- NA\n",
    "coding_data$prpos_us <- NA\n",
    "coding_data$prpos_chn <- NA\n",
    "coding_data$prpos_sko <- NA\n",
    "coding_data$prpos_nko <- NA\n",
    "for (i in 1:1000){\n",
    "  coding_data$prneg_us[i] <- mean(as.numeric(uscode_neg[i,]))\n",
    "  coding_data$prneg_chn[i] <- mean(as.numeric(chncode_neg[i,]))\n",
    "  coding_data$prneg_sko[i] <- mean(as.numeric(skocode_neg[i,]))\n",
    "  coding_data$prneg_nko[i] <- mean(as.numeric(nkocode_neg[i,]))\n",
    "  coding_data$prpos_us[i] <- mean(as.numeric(uscode_pos[i,]))\n",
    "  coding_data$prpos_chn[i] <- mean(as.numeric(chncode_pos[i,]))\n",
    "  coding_data$prpos_sko[i] <- mean(as.numeric(skocode_pos[i,]))\n",
    "  coding_data$prpos_nko[i] <- mean(as.numeric(nkocode_pos[i,]))\n",
    "}\n",
    "\n",
    "## Set rows for the sampling population\n",
    "samplepoprows <- which(hldata$id_all %in% sample_selection$id_all)\n",
    "\n",
    "## Merge Coding Values into Full Dataset\n",
    "hldata$prneg_us <- NA\n",
    "hldata$prneg_chn <- NA\n",
    "hldata$prneg_sko <- NA\n",
    "hldata$prneg_nko <- NA\n",
    "hldata$prpos_us <- NA\n",
    "hldata$prpos_chn <- NA\n",
    "hldata$prpos_sko <- NA\n",
    "hldata$prpos_nko <- NA\n",
    "\n",
    "hldata[samplepoprows,]$prneg_us[order(sample_selection$US_SID)][1:1000] <- \n",
    "  coding_data$prneg_us[order(coding_data$id)]\n",
    "hldata[samplepoprows,]$prneg_chn[order(sample_selection$CHN_SID)][1:1000] <- \n",
    "  coding_data$prneg_chn[order(coding_data$id)]\n",
    "hldata[samplepoprows,]$prneg_sko[order(sample_selection$KOR_SID)][1:1000] <- \n",
    "  coding_data$prneg_sko[order(coding_data$id)]\n",
    "hldata[samplepoprows,]$prneg_nko[order(sample_selection$NKOR_SID)][1:1000] <- \n",
    "  coding_data$prneg_nko[order(coding_data$id)]\n",
    "hldata[samplepoprows,]$prpos_us[order(sample_selection$US_SID)][1:1000] <- \n",
    "  coding_data$prpos_us[order(coding_data$id)]\n",
    "hldata[samplepoprows,]$prpos_chn[order(sample_selection$CHN_SID)][1:1000] <- \n",
    "  coding_data$prpos_chn[order(coding_data$id)]\n",
    "hldata[samplepoprows,]$prpos_sko[order(sample_selection$KOR_SID)][1:1000] <- \n",
    "  coding_data$prpos_sko[order(coding_data$id)]\n",
    "hldata[samplepoprows,]$prpos_nko[order(sample_selection$NKOR_SID)][1:1000] <- \n",
    "  coding_data$prpos_nko[order(coding_data$id)]\n",
    "\n",
    "hldata$train_us <-  (!is.na(hldata$prneg_us))*1\n",
    "hldata$train_chn <-  (!is.na(hldata$prneg_chn))*1\n",
    "hldata$train_sko <-  (!is.na(hldata$prneg_sko))*1\n",
    "hldata$train_nko <-  (!is.na(hldata$prneg_nko))*1\n",
    "\n",
    "hldata$cdneg_us <- (hldata$prneg_us >= 0.5)*1\n",
    "hldata$cdneg_chn <- (hldata$prneg_chn >= 0.5)*1\n",
    "hldata$cdneg_sko <- (hldata$prneg_sko >= 0.5)*1\n",
    "hldata$cdneg_nko <- (hldata$prneg_nko >= 0.5)*1\n",
    "\n",
    "hldata$cdpos_us <- (hldata$prpos_us >= 0.5)*1\n",
    "hldata$cdpos_chn <- (hldata$prpos_chn >= 0.5)*1\n",
    "hldata$cdpos_sko <- (hldata$prpos_sko >= 0.5)*1\n",
    "hldata$cdpos_nko <- (hldata$prpos_nko >= 0.5)*1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>0</th><th scope=col>1</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>US (Negative)</th><td>715</td><td>272</td></tr>\n",
       "\t<tr><th scope=row>China (Negative)</th><td>743</td><td>253</td></tr>\n",
       "\t<tr><th scope=row>South Korea (Negative)</th><td>882</td><td>111</td></tr>\n",
       "\t<tr><th scope=row>North Korea (Negative)</th><td>477</td><td>472</td></tr>\n",
       "\t<tr><th scope=row>US (Positive)</th><td>852</td><td>135</td></tr>\n",
       "\t<tr><th scope=row>China (Positive)</th><td>876</td><td>120</td></tr>\n",
       "\t<tr><th scope=row>South Korea (Positive)</th><td>888</td><td>105</td></tr>\n",
       "\t<tr><th scope=row>North Korea (Positive)</th><td>770</td><td>179</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       "  & 0 & 1\\\\\n",
       "\\hline\n",
       "\tUS (Negative) & 715 & 272\\\\\n",
       "\tChina (Negative) & 743 & 253\\\\\n",
       "\tSouth Korea (Negative) & 882 & 111\\\\\n",
       "\tNorth Korea (Negative) & 477 & 472\\\\\n",
       "\tUS (Positive) & 852 & 135\\\\\n",
       "\tChina (Positive) & 876 & 120\\\\\n",
       "\tSouth Korea (Positive) & 888 & 105\\\\\n",
       "\tNorth Korea (Positive) & 770 & 179\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | 0 | 1 | \n",
       "|---|---|---|---|---|---|---|---|\n",
       "| US (Negative) | 715 | 272 | \n",
       "| China (Negative) | 743 | 253 | \n",
       "| South Korea (Negative) | 882 | 111 | \n",
       "| North Korea (Negative) | 477 | 472 | \n",
       "| US (Positive) | 852 | 135 | \n",
       "| China (Positive) | 876 | 120 | \n",
       "| South Korea (Positive) | 888 | 105 | \n",
       "| North Korea (Positive) | 770 | 179 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "                       0   1  \n",
       "US (Negative)          715 272\n",
       "China (Negative)       743 253\n",
       "South Korea (Negative) 882 111\n",
       "North Korea (Negative) 477 472\n",
       "US (Positive)          852 135\n",
       "China (Positive)       876 120\n",
       "South Korea (Positive) 888 105\n",
       "North Korea (Positive) 770 179"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tx <- rbind(t(table(hldata$cdneg_us)),\n",
    "            t(table(hldata$cdneg_chn)),\n",
    "            t(table(hldata$cdneg_sko)),\n",
    "            t(table(hldata$cdneg_nko)),\n",
    "            t(table(hldata$cdpos_us)),\n",
    "            t(table(hldata$cdpos_chn)),\n",
    "            t(table(hldata$cdpos_sko)),\n",
    "            t(table(hldata$cdpos_nko)))\n",
    "row.names(tx) <- c(\"US (Negative)\",\"China (Negative)\",\"South Korea (Negative)\",\"North Korea (Negative)\",\n",
    "                   \"US (Positive)\",\"China (Positive)\",\"South Korea (Positive)\",\"North Korea (Positive)\")\n",
    "xtable(tx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Code with Consistent Coding Rule\n",
    "\n",
    "As explained in the previous section, the training code with \"consistent\" coding scheme is another way to construct codes. This variable is also merged to the full dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### 2. Use the Consistent Coding Scheme (Stata File) ####\n",
    "\n",
    "## Set rows for the sampling population\n",
    "samplepoprows <- which(hldata$id_all %in% sample_selection$id_all)\n",
    "\n",
    "## Create Variables\n",
    "hldata$cdneg_us2 <- NA\n",
    "hldata$cdneg_chn2 <- NA\n",
    "hldata$cdneg_sko2 <- NA\n",
    "hldata$cdneg_nko2 <- NA\n",
    "hldata$cdpos_us2 <- NA\n",
    "hldata$cdpos_chn2 <- NA\n",
    "hldata$cdpos_sko2 <- NA\n",
    "hldata$cdpos_nko2 <- NA\n",
    "\n",
    "## Merge Data\n",
    "hldata[samplepoprows,]$cdneg_us2[order(sample_selection$US_SID)][1:1000] <- \n",
    "  (coding_data$us_final[order(coding_data$id)]==1)*1\n",
    "hldata[samplepoprows,]$cdneg_chn2[order(sample_selection$CHN_SID)][1:1000] <- \n",
    "  (coding_data$chn_final[order(coding_data$id)]==1)*1\n",
    "hldata[samplepoprows,]$cdneg_sko2[order(sample_selection$KOR_SID)][1:1000] <- \n",
    "  (coding_data$sko_final[order(coding_data$id)]==1)*1\n",
    "hldata[samplepoprows,]$cdneg_nko2[order(sample_selection$NKOR_SID)][1:1000] <- \n",
    "  (coding_data$nko_final[order(coding_data$id)]==1)*1\n",
    "hldata[samplepoprows,]$cdpos_us2[order(sample_selection$US_SID)][1:1000] <- \n",
    "  (coding_data$us_final[order(coding_data$id)]==3)*1\n",
    "hldata[samplepoprows,]$cdpos_chn2[order(sample_selection$CHN_SID)][1:1000] <- \n",
    "  (coding_data$chn_final[order(coding_data$id)]==3)*1\n",
    "hldata[samplepoprows,]$cdpos_sko2[order(sample_selection$KOR_SID)][1:1000] <- \n",
    "  (coding_data$sko_final[order(coding_data$id)]==3)*1\n",
    "hldata[samplepoprows,]$cdpos_nko2[order(sample_selection$NKOR_SID)][1:1000] <- \n",
    "  (coding_data$nko_final[order(coding_data$id)]==3)*1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>0</th><th scope=col>1</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>US (Negative)</th><td>723</td><td>264</td></tr>\n",
       "\t<tr><th scope=row>China (Negative)</th><td>745</td><td>251</td></tr>\n",
       "\t<tr><th scope=row>South Korea (Negative)</th><td>882</td><td>111</td></tr>\n",
       "\t<tr><th scope=row>North Korea (Negative)</th><td>540</td><td>409</td></tr>\n",
       "\t<tr><th scope=row>US (Positive)</th><td>854</td><td>133</td></tr>\n",
       "\t<tr><th scope=row>China (Positive)</th><td>876</td><td>120</td></tr>\n",
       "\t<tr><th scope=row>South Korea (Positive)</th><td>889</td><td>104</td></tr>\n",
       "\t<tr><th scope=row>North Korea (Positive)</th><td>792</td><td>157</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       "  & 0 & 1\\\\\n",
       "\\hline\n",
       "\tUS (Negative) & 723 & 264\\\\\n",
       "\tChina (Negative) & 745 & 251\\\\\n",
       "\tSouth Korea (Negative) & 882 & 111\\\\\n",
       "\tNorth Korea (Negative) & 540 & 409\\\\\n",
       "\tUS (Positive) & 854 & 133\\\\\n",
       "\tChina (Positive) & 876 & 120\\\\\n",
       "\tSouth Korea (Positive) & 889 & 104\\\\\n",
       "\tNorth Korea (Positive) & 792 & 157\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | 0 | 1 | \n",
       "|---|---|---|---|---|---|---|---|\n",
       "| US (Negative) | 723 | 264 | \n",
       "| China (Negative) | 745 | 251 | \n",
       "| South Korea (Negative) | 882 | 111 | \n",
       "| North Korea (Negative) | 540 | 409 | \n",
       "| US (Positive) | 854 | 133 | \n",
       "| China (Positive) | 876 | 120 | \n",
       "| South Korea (Positive) | 889 | 104 | \n",
       "| North Korea (Positive) | 792 | 157 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "                       0   1  \n",
       "US (Negative)          723 264\n",
       "China (Negative)       745 251\n",
       "South Korea (Negative) 882 111\n",
       "North Korea (Negative) 540 409\n",
       "US (Positive)          854 133\n",
       "China (Positive)       876 120\n",
       "South Korea (Positive) 889 104\n",
       "North Korea (Positive) 792 157"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tx <- rbind(t(table(hldata$cdneg_us2)),\n",
    "            t(table(hldata$cdneg_chn2)),\n",
    "            t(table(hldata$cdneg_sko2)),\n",
    "            t(table(hldata$cdneg_nko2)),\n",
    "            t(table(hldata$cdpos_us2)),\n",
    "            t(table(hldata$cdpos_chn2)),\n",
    "            t(table(hldata$cdpos_sko2)),\n",
    "            t(table(hldata$cdpos_nko2)))\n",
    "row.names(tx) <- c(\"US (Negative)\",\"China (Negative)\",\"South Korea (Negative)\",\"North Korea (Negative)\",\n",
    "                   \"US (Positive)\",\"China (Positive)\",\"South Korea (Positive)\",\"North Korea (Positive)\")\n",
    "xtable(tx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Word Count Variables & Country Subsets\n",
    "\n",
    "Some new variables are added to the dataset. Then I split the full dataset into country subsets (for US, China, South Korea and North Korea)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#########################################\n",
    "## Create New Variables & Data Subsets ##\n",
    "#########################################\n",
    "\n",
    "## Date Data Add Variables ##\n",
    "hldata$Asahi[is.na(hldata$Asahi)]<-0\n",
    "hldata$Yomiuri[is.na(hldata$Yomiuri)]<-0\n",
    "hldata$Both <- hldata$Asahi*(4/9)+hldata$Yomiuri*(5/9) ## Headline Count\n",
    "hldata$Asahi_w <- hldata$Asahi*hldata$wcount # Word count for Asahi\n",
    "hldata$Yomiuri_w <- hldata$Yomiuri*hldata$wcount # Word count Yomiuri\n",
    "hldata$Both_w <- hldata$Asahi_w*(4/9)+hldata$Yomiuri_w*(5/9)\n",
    "## Note that Weighting in \"Both\" variable is made on the fact that \n",
    "## Actual circulation of two newspapers are roughly 4:5\n",
    "\n",
    "# Create Subset Data\n",
    "usdata<-subset(hldata, us==1)\n",
    "chndata<-subset(hldata, chn==1)\n",
    "skordata<-subset(hldata, kor==1)\n",
    "nkordata<-subset(hldata, nkor==1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Isomorphic Analysis\n",
    "\n",
    "Here, isomorphic analysis is applied to separate the headline by words, using <code>RMecab</code>. This data list is used in the procedure to search for keywords. Also, word appearance matrix is created for the use in machine learning. In the word appearance matrix, all nouns, adjectives, verbs, auxiliary verbs, prefixes, and adverbs are included. (This takes time.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#########################\n",
    "## Isomorphic Analysis ##\n",
    "#########################\n",
    "\n",
    "# Conduct Isomorphic Analysis (Use User Dictionary for user-defined words)\n",
    "MecabRes<-RMeCabDF(dataf=hldata,coln=\"Headline\",\n",
    "                   mypref=1,\n",
    "                   dic=\"./codes/userdictionary/user.dic\")\n",
    "# Results by Country \n",
    "usMecabRes <- MecabRes[which(hldata$us==1)]\n",
    "chnMecabRes<- MecabRes[which(hldata$chn==1)]\n",
    "skorMecabRes<- MecabRes[which(hldata$kor==1)]\n",
    "nkorMecabRes<- MecabRes[which(hldata$nkor==1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>名詞</dt>\n",
       "\t\t<dd>'米'</dd>\n",
       "\t<dt>名詞</dt>\n",
       "\t\t<dd>'国務'</dd>\n",
       "\t<dt>名詞</dt>\n",
       "\t\t<dd>'次官補'</dd>\n",
       "\t<dt>記号</dt>\n",
       "\t\t<dd>'、'</dd>\n",
       "\t<dt>名詞</dt>\n",
       "\t\t<dd>'懸案'</dd>\n",
       "\t<dt>名詞</dt>\n",
       "\t\t<dd>'協議'</dd>\n",
       "\t<dt>助詞</dt>\n",
       "\t\t<dd>'へ'</dd>\n",
       "\t<dt>名詞</dt>\n",
       "\t\t<dd>'あす'</dd>\n",
       "\t<dt>名詞</dt>\n",
       "\t\t<dd>'来日'</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[名詞] '米'\n",
       "\\item[名詞] '国務'\n",
       "\\item[名詞] '次官補'\n",
       "\\item[記号] '、'\n",
       "\\item[名詞] '懸案'\n",
       "\\item[名詞] '協議'\n",
       "\\item[助詞] 'へ'\n",
       "\\item[名詞] 'あす'\n",
       "\\item[名詞] '来日'\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "名詞\n",
       ":   '米'名詞\n",
       ":   '国務'名詞\n",
       ":   '次官補'記号\n",
       ":   '、'名詞\n",
       ":   '懸案'名詞\n",
       ":   '協議'助詞\n",
       ":   'へ'名詞\n",
       ":   'あす'名詞\n",
       ":   '来日'\n",
       "\n"
      ],
      "text/plain": [
       "    名詞     名詞     名詞     記号     名詞     名詞     助詞     名詞 \n",
       "    \"米\"   \"国務\" \"次官補\"     \"、\"   \"懸案\"   \"協議\"     \"へ\"   \"あす\" \n",
       "    名詞 \n",
       "  \"来日\" "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "usMecabRes[[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to make data frame\n",
      "\n",
      "to make data frame\n",
      "\n",
      "to make data frame\n",
      "\n",
      "to make data frame\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create Word Matrix by Country\n",
    "createWrdMat <- function(dt) docMatrixDF(dt[,\"Headline\"], \n",
    "                                         pos = c(\"名詞\",\"形容詞\",\"動詞\",\"助動詞\",\"接頭詞\",\"副詞\"), \n",
    "                                         #\"助動詞\",\"助詞\",\"接続詞\",\"接頭詞\",\"副詞\",\"感動詞\",\"記号\", \"フィラー\", \"その他\"\n",
    "                                         dic=\"./codes/userdictionary/user.dic\",\n",
    "                                         minFreq = 2)\n",
    "usWrdMat <- as.data.frame(t(createWrdMat(usdata)))\n",
    "chnWrdMat <- as.data.frame(t(createWrdMat(chndata)))\n",
    "skorWrdMat <- as.data.frame(t(createWrdMat(skordata)))\n",
    "nkorWrdMat <- as.data.frame(t(createWrdMat(nkordata)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>?</th><th scope=col>，</th><th scope=col>．</th><th scope=col>・</th><th scope=col>％</th><th scope=col>０</th><th scope=col>１</th><th scope=col>１０月</th><th scope=col>１１月</th><th scope=col>１２月</th><th scope=col>...</th><th scope=col>枠組み</th><th scope=col>湾岸</th><th scope=col>丼</th><th scope=col>姜</th><th scope=col>拉致</th><th scope=col>瀋陽</th><th scope=col>盧</th><th scope=col>絆</th><th scope=col>胚</th><th scope=col>趙</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>OBS.1</th><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>...</td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td></tr>\n",
       "\t<tr><th scope=row>OBS.2</th><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>1  </td><td>0  </td><td>0  </td><td>0  </td><td>...</td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td></tr>\n",
       "\t<tr><th scope=row>OBS.3</th><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>1  </td><td>1  </td><td>0  </td><td>0  </td><td>0  </td><td>...</td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td></tr>\n",
       "\t<tr><th scope=row>OBS.4</th><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>1  </td><td>1  </td><td>0  </td><td>0  </td><td>0  </td><td>...</td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td></tr>\n",
       "\t<tr><th scope=row>OBS.5</th><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>...</td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td></tr>\n",
       "\t<tr><th scope=row>OBS.6</th><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>...</td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll}\n",
       "  & ? & ， & ． & ・ & ％ & ０ & １ & １０月 & １１月 & １２月 & ... & 枠組み & 湾岸 & 丼 & 姜 & 拉致 & 瀋陽 & 盧 & 絆 & 胚 & 趙\\\\\n",
       "\\hline\n",
       "\tOBS.1 & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & ... & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0  \\\\\n",
       "\tOBS.2 & 0   & 0   & 0   & 0   & 0   & 0   & 1   & 0   & 0   & 0   & ... & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0  \\\\\n",
       "\tOBS.3 & 0   & 0   & 0   & 0   & 0   & 1   & 1   & 0   & 0   & 0   & ... & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0  \\\\\n",
       "\tOBS.4 & 0   & 0   & 0   & 0   & 0   & 1   & 1   & 0   & 0   & 0   & ... & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0  \\\\\n",
       "\tOBS.5 & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & ... & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0  \\\\\n",
       "\tOBS.6 & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & ... & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | ? | ， | ． | ・ | ％ | ０ | １ | １０月 | １１月 | １２月 | ... | 枠組み | 湾岸 | 丼 | 姜 | 拉致 | 瀋陽 | 盧 | 絆 | 胚 | 趙 | \n",
       "|---|---|---|---|---|---|\n",
       "| OBS.1 | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | ... | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | \n",
       "| OBS.2 | 0   | 0   | 0   | 0   | 0   | 0   | 1   | 0   | 0   | 0   | ... | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | \n",
       "| OBS.3 | 0   | 0   | 0   | 0   | 0   | 1   | 1   | 0   | 0   | 0   | ... | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | \n",
       "| OBS.4 | 0   | 0   | 0   | 0   | 0   | 1   | 1   | 0   | 0   | 0   | ... | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | \n",
       "| OBS.5 | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | ... | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | \n",
       "| OBS.6 | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | ... | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "      ? ， ． ・ ％ ０ １ １０月 １１月 １２月 ... 枠組み 湾岸 丼 姜 拉致 瀋陽\n",
       "OBS.1 0 0  0  0  0  0  0  0      0      0      ... 0      0    0  0  0    0   \n",
       "OBS.2 0 0  0  0  0  0  1  0      0      0      ... 0      0    0  0  0    0   \n",
       "OBS.3 0 0  0  0  0  1  1  0      0      0      ... 0      0    0  0  0    0   \n",
       "OBS.4 0 0  0  0  0  1  1  0      0      0      ... 0      0    0  0  0    0   \n",
       "OBS.5 0 0  0  0  0  0  0  0      0      0      ... 0      0    0  0  0    0   \n",
       "OBS.6 0 0  0  0  0  0  0  0      0      0      ... 0      0    0  0  0    0   \n",
       "      盧 絆 胚 趙\n",
       "OBS.1 0  0  0  0 \n",
       "OBS.2 0  0  0  0 \n",
       "OBS.3 0  0  0  0 \n",
       "OBS.4 0  0  0  0 \n",
       "OBS.5 0  0  0  0 \n",
       "OBS.6 0  0  0  0 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(usWrdMat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Datasets\n",
    "\n",
    "All headline level country subsets and word appearance matrix are saved to <code>data</code> directory. Also, the R environment is saved to the same directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################\n",
    "## Save Image ##\n",
    "################\n",
    "\n",
    "#load(\"data_heavy/v3_Data_HeadlineWrdMat.Rdata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save.image(\"data/v3_Data2_HeadlineWrdMat.Rdata\")\n",
    "\n",
    "## Save Country Subsets\n",
    "write.csv(usdata,\"data/usdata.csv\", fileEncoding = \"CP932\",row.names=FALSE)\n",
    "write.csv(chndata,\"data/chndata.csv\", fileEncoding = \"CP932\",row.names=FALSE)\n",
    "write.csv(skordata,\"data/skordata.csv\", fileEncoding = \"CP932\",row.names=FALSE)\n",
    "write.csv(nkordata,\"data/nkordata.csv\", fileEncoding = \"CP932\",row.names=FALSE)\n",
    "\n",
    "## Save Word Appearance Matrix\n",
    "write.csv(usWrdMat,\"data/usWrdMat.csv\", fileEncoding = \"CP932\",row.names=FALSE)\n",
    "write.csv(chnWrdMat,\"data/chnWrdMat.csv\", fileEncoding = \"CP932\",row.names=FALSE)\n",
    "write.csv(skorWrdMat,\"data/skorWrdMat.csv\", fileEncoding = \"CP932\",row.names=FALSE)\n",
    "write.csv(nkorWrdMat,\"data/nkorWrdMat.csv\", fileEncoding = \"CP932\",row.names=FALSE)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
